{"cells":[{"cell_type":"code","source":["'''\n","Project\n","Forecasting Stock Market Indices Using the Recurrent Neural Network Based Hybrid Models: CNN-LSTM, GRU-CNN, and Ensemble Models\n","'''"],"metadata":{"id":"O35MEuFqoqv2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M3WIRpZ1ir1H"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import warnings, os, shutil, random, sys\n","\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import Adam, RMSprop, Adadelta, Adagrad, Ftrl\n","from tensorflow.keras import initializers, metrics\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from tensorflow.keras.layers import BatchNormalization, Dropout\n","from tensorflow.keras.layers import MaxPool1D, GlobalMaxPooling1D\n","from tensorflow.keras import layers\n","\n","\n","SEED = 777\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","warnings.filterwarnings(action='ignore') \n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","\n","print(\"python version:\",sys.version)\n","print(\"numpy version:\", np.__version__)        \n","print(\"tensorflow version:\", tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGNakHGhir1N"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jv5eldXTir1O"},"outputs":[],"source":["KERNEL_INIT = initializers.glorot_uniform(seed=SEED)\n","Re_INIT = initializers.Orthogonal(gain=1.0, seed=SEED)\n","        \n","def last_time_step_mse(y_true, y_pred):\n","    return metrics.mean_squared_error(y_true[:,-1], y_pred[:,-1])\n","def last_time_step_mae(y_true, y_pred):\n","    return metrics.mean_absolute_error(y_true[:,-1], y_pred[:,-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYD9LSU9ir1O"},"outputs":[],"source":["import pickle\n","\n","def save_data(data, path):\n","    with open(path, 'wb') as f:\n","        pickle.dump(data, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zAAO0CaOir1P"},"outputs":[],"source":["'''\n","    Load Pickled Data\n","'''\n","import pickle\n","\n","def load_data(path):\n","    loaded = None\n","    \n","    with open(path, 'rb') as fr:\n","        loaded = pickle.load(fr)\n","        \n","    return loaded\n","\n","PREPROC_ALL_TRAIN_DATA = load_data('./save_files3/PREPROC_ALL_TRAIN_DATA.pickle')\n","PREPROC_ALL_TEST_DATA = load_data('./save_files3/PREPROC_ALL_TEST_DATA.pickle')\n","SCALER = load_data('./save_files3/SCALER.pickle')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGfUOzOOir1Q"},"outputs":[],"source":["def make_dataset(x, y, input_wd, pred_wd):\n","    mk_x = []   \n","    mk_y = []  \n","    for i in range(len(x)-input_wd-pred_wd+1):\n","        mk_x.append(x[i:i+input_wd])\n","        mk_y.append(y[i+input_wd:i+input_wd+pred_wd])\n","    return np.array(mk_x), np.array(mk_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEZCvCMYir1Q"},"outputs":[],"source":["'''\n","    Load preprocessed data\n","'''\n","def get_preprocess_data(feature_code = \"OHMLVC\", data_code = \"DJI\", duration = \"P0019\", dataset_split=\"T10\"):\n","    train_x_key = f\"{data_code}_{duration}_{dataset_split}_TRX\"\n","    train_y_key = f\"{data_code}_{duration}_{dataset_split}_TRY\"\n","    \n","    test_x_key = f\"{data_code}_{duration}_{dataset_split}_TEX\"\n","    test_y_key = f\"{data_code}_{duration}_{dataset_split}_TEY\"\n","    \n","    scaler_key = f\"{data_code}_{duration}\"\n","    \n","    return (\n","        PREPROC_ALL_TRAIN_DATA[feature_code][train_x_key],\n","        PREPROC_ALL_TRAIN_DATA[feature_code][train_y_key],\n","        \n","        PREPROC_ALL_TEST_DATA[feature_code][test_x_key],\n","        PREPROC_ALL_TEST_DATA[feature_code][test_y_key],\n","        \n","        SCALER[feature_code][scaler_key][\"x\"],\n","        SCALER[feature_code][scaler_key][\"y\"],\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DA9_-yRzir1R"},"outputs":[],"source":["'''\n","    CNN_LSTM\n","'''\n","def cnn_lstm(in_window, n_feature, x, y, x_test, y_test, pred_wd, EPOCHS, OPT, lr, verbose):\n","    model = Sequential()\n","    model.add(Input(shape=(in_window, n_feature)))\n","    \n","    model.add(Conv1D(\n","         filters = 32,\n","         kernel_size = 3,\n","         strides = 1,\n","         padding = \"causal\",\n","        activation = \"relu\"\n","     ))    \n","    model.add(LSTM(128, return_sequences=False, stateful=False,\n","                    kernel_initializer=KERNEL_INIT,\n","                    recurrent_initializer=Re_INIT,\n","                    bias_initializer='zeros'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.2, seed=777))    \n","    model.add(Dense(pred_wd,kernel_initializer= KERNEL_INIT,bias_initializer=\"zeros\", activation='relu'))\n","    if OPT==\"ADAM\":\n","        opt=Adam(lr=lr)\n","    else:\n","        opt=RMSprop(lr=lr)\n","    \n","    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, \n","                  metrics=[last_time_step_mse, last_time_step_mae])\n","    \n","    earlystopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n","    filename = os.path.join('cnn_lstm', 'ckeckpointer.ckpt')\n","    checkpoint = ModelCheckpoint(filename, \n","                                 save_weights_only=True, \n","                                 save_best_only=True, \n","                                 monitor='val_loss', \n","                                 verbose=0)\n","    \n","    hist = model.fit(x, y, batch_size=32, epochs=EPOCHS, validation_split=0.1, \n","                     shuffle=False, verbose=0, callbacks=[earlystopping, checkpoint])   \n","    return model, filename\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nayroNMir1R"},"outputs":[],"source":["'''\n","    GRU_CNN Model\n","'''\n","def gru_cnn(in_window, n_feature,x,y,x_test, y_test, pred_wd, EPOCHS, OPT, lr, verbose):\n","    model = Sequential()\n","    \n","    model.add(GRU(128,input_shape=[in_window, n_feature],\n","                      kernel_initializer=KERNEL_INIT,\n","                      recurrent_initializer=Re_INIT,\n","                      return_sequences=True,\n","                      bias_initializer='zeros'))\n","     \n","    model.add(Conv1D(\n","         filters = 32,\n","         kernel_size = 3,\n","         strides = 1,\n","         padding = \"causal\",\n","        activation = \"relu\"\n","     ))\n","    \n","    model.add(GlobalMaxPooling1D())\n","\n","    model.add(Dense(10, kernel_initializer= KERNEL_INIT,bias_initializer=\"zeros\", activation='relu'))\n","\n","    model.add(Dropout(0.2, seed=777))\n","    \n","    model.add(Dense(pred_wd,kernel_initializer= KERNEL_INIT,bias_initializer=\"zeros\", activation='relu'))\n","    \n","    if OPT==\"ADAM\":\n","        opt=Adam(lr=lr)\n","    else:\n","        opt=RMSprop(lr=lr)\n","        \n","    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, \n","                  metrics=[last_time_step_mse, last_time_step_mae])\n","    \n","    earlystopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n","    filename = os.path.join('gru_cnn', 'ckeckpointer.ckpt')\n","    checkpoint = ModelCheckpoint(filename, \n","                                 save_weights_only=True, \n","                                 save_best_only=True, \n","                                 monitor='val_loss', \n","                                 verbose=0)\n","    hist = model.fit(x,y,batch_size=32, epochs=EPOCHS, validation_split=0.1, \n","                     shuffle=False, verbose=0, callbacks=[earlystopping, checkpoint]) \n","    \n","    return model, filename"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HaEE5qTsir1S"},"outputs":[],"source":["def train_model(model_type, name, iw, pw, n_features, trd_x, trd_y, ted_x, ted_y, lr, epochs, verbose):\n","    model = None\n","    hist = None\n","\n","    if model_type == 'gru_cnn':\n","        model, filename = gru_cnn(iw, n_features, trd_x, trd_y, ted_x, ted_y, pw, epochs, 'RSMProp', lr, verbose)\n","                \n","    if model_type == 'cnn_lstm':\n","        model, filename = cnn_lstm(iw, n_features, trd_x, trd_y, ted_x, ted_y, pw, epochs, 'RSMProp',lr, verbose)\n","    \n","    model.load_weights(filename)\n","    y_pred = model.predict(ted_x)\n","   \n","    return ted_y[:,-1], y_pred[:,-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"tiIDXs92ir1S"},"outputs":[],"source":["FEATURES = [\n","#     \"OHLV\",\n","#     \"MV\",\n","    #\"MVC\",\n","    \"OHMLVC\"\n","]\n","\n","DURATIONS = [\n","#     \"P0019\",\n","#     \"P1719\",\n","    \"P1921\"\n","]\n","\n","DATA = [\n","    \"DJI\",\n","    \"US500\",\n","    \"DAX\",\n","\n","]\n","\n","IW = [\n","     5\n","#     21,\n","#    42\n","]\n","\n","PW = [\n","    1\n","#    5\n","]\n","\n","MODELS = [\n","#   \"cnn_lstm\", # Conv -> LSTM BLock * 22 -> Dense\n","#   \"lstm_cnn\", # Lstm -> Conv -> Dense\n","#   \"lstm_cnn_gmp\", # Lstm -> Conv -> GMP1D > Dense10 -> Dense\n","  \"gru_cnn\", # GRU -> Conv1d -> GMP1D -> Dense -> Dropout -> Dense\n","  \"cnn_lstm\"\n","]\n","\n","true_result = []\n","pred_result = []\n","for feature in FEATURES: #4\n","    for duration in DURATIONS: #3\n","        for data in DATA: #5\n","            for iw in IW: #2\n","                for pw in PW: #2\n","                    for model in MODELS: #4\n","                        model_name = f\"{iw}_{pw}_{feature}_{data}_{duration}_{model}\"\n","                        \n","                        tf.keras.backend.clear_session()\n","                        \n","                        trd_x, trd_y, ted_x, ted_y, scaler_x, scaler_y = get_preprocess_data(\n","                            feature_code=feature, \n","                            data_code=data, \n","                            duration=duration, \n","                            dataset_split='T20'\n","                        )\n","\n","                        train_x_dataset, train_y_dataset = make_dataset(trd_x, trd_y, iw, pw)\n","                        test_x_dataset, test_y_dataset = make_dataset(ted_x, ted_y, iw, pw)\n","\n","                        ted_y[:,-1], y_pred[:,-1] = train_model(\n","                                    model,\n","                                    model_name,\n","                                    iw, \n","                                    pw, \n","                                    len(feature), \n","                                    train_x_dataset, \n","                                    train_y_dataset, \n","                                    test_x_dataset, \n","                                    test_y_dataset, \n","                                    lr=0.0005,\n","                                    epochs=1,\n","                                    verbose=0)\n","                        \n","                        true_result.append(ted_y[:,-1])\n","                        pred_result.append(y_pred[:,-1])"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}